import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from dotenv import load_dotenv
import nest_asyncio
import asyncio
from pathlib import Path
load_dotenv()
nest_asyncio.apply() # è¿è¡ŒåµŒå¥—ä½¿ç”¨asyncioå¾ªç¯

from llama_parse import LlamaParse, ResultType
from llama_index.core.node_parser import HierarchicalNodeParser, get_leaf_nodes
from llama_index.core import Settings, VectorStoreIndex, StorageContext
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.qdrant import QdrantVectorStore
import qdrant_client

PDF_PATH = Path(__file__).resolve().parents[1] / "data" / "æ·±åº¦å­¦ä¹ è¿›é˜¶_è‡ªç„¶è¯­è¨€å¤„ç†_æ–‹è—¤åº·æ¯….pdf"

QDRANT_URL = "http://localhost:6333"
COLLECTION_NAME = "edu_matrix_v2"

async def main():
    print(f"ğŸš€ [Async] å¼€å§‹è§£ææ–‡ä»¶: {PDF_PATH} ...")

    # åˆå§‹åŒ–è§£æå™¨
    parser = LlamaParse(
        result_type=ResultType.MD, # è¾“å‡ºæ ¼å¼ä¸ºmarkdown
        verbose=True, # åœ¨ç»ˆç«¯æ‰“å°è¯¦ç»†çš„è¿›åº¦æ¡å’Œæ—¥å¿—
        language="ch_sim",
        num_workers=4,
        api_key=os.getenv("LLAMACLOUD_API_KEY") or "",
        fast_mode=False,
        system_prompt="""
        è¿™æ˜¯ä¸€ä¸ªè®¡ç®—æœºç§‘å­¦æ•™æã€‚
        1. è¯·ç²¾ç¡®ä¿ç•™æ‰€æœ‰çš„æ•°å­¦å…¬å¼ï¼ˆä½¿ç”¨ LaTeX æ ¼å¼ï¼‰ã€‚
        2. ä¸è¦è¾“å‡ºé¡µçœ‰å’Œé¡µè„šçš„é¡µç ä¿¡æ¯ã€‚
        3. å¦‚æœé‡åˆ°è¡¨æ ¼ï¼Œè¯·å°†å…¶è½¬æ¢ä¸º Markdown è¡¨æ ¼ã€‚
        4. ä¿æŒæ­£æ–‡çš„è¿è´¯æ€§ã€‚ä¸è¦è¾“å‡º 'Here are some facts' è¿™ç±»æ— å…³æ–‡å­—ã€‚
        """,
    )

    print("â³ æ­£åœ¨è¯·æ±‚ LlamaCloud API è¿›è¡Œäº‘ç«¯è§£æï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åç§’ï¼‰...")
    documents = await parser.aload_data(str(PDF_PATH))

    # print("\n--- [Preview] Markdown æºç é¢„è§ˆ ---")
    # print(documents[0].text[:500])

    # æ„å»ºparent-childç´¢å¼•ç­–ç•¥
    node_parser = HierarchicalNodeParser.from_defaults(
        chunk_sizes=[1000, 200], # çˆ¶å—ä»¥åŠå­—å—å„è‡ªçš„tokensæ•°
    )

    print("âœ‚ï¸  æ­£åœ¨æ‰§è¡Œæœ¬åœ°åˆ‡åˆ† (Parent-Child Strategy)...")
    # è¿™ä¸€æ­¥æ˜¯åœ¨æœ¬åœ° CPU è¿è¡Œçš„ï¼Œé€Ÿåº¦å¾ˆå¿«
    nodes = node_parser.get_nodes_from_documents(documents)

    # è·å–æ‰€æœ‰çš„â€œå¶å­èŠ‚ç‚¹â€ï¼ˆä¹Ÿå°±æ˜¯æœ€åº•å±‚çš„ Child Chunkï¼Œé‚£ 200 tokens çš„å—ï¼‰
    leaf_nodes = get_leaf_nodes(nodes)

    print(f"âœ… æ•°æ®æ²»ç†å®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡æ•°æ®:")
    print(f"  - æ€»èŠ‚ç‚¹æ•° (Parent + Child): {len(nodes)}")
    print(f"  - å¾…å­˜å…¥å‘é‡åº“çš„å­èŠ‚ç‚¹æ•° (Child Nodes): {len(leaf_nodes)}")

    client = qdrant_client.QdrantClient(url=QDRANT_URL)

    vector_store = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
    )

    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    print("ğŸ§  æ­£åœ¨åŠ è½½ BGE-M3 åµŒå…¥æ¨¡å‹ (é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½)...")
    embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-m3",
        trust_remote_code=True
    )
    Settings.embed_model = embed_model # å…¨å±€é»˜è®¤ä½¿ç”¨è¯¥æ¨¡å‹åµŒå…¥å‘é‡

    index = VectorStoreIndex( # è‡ªåŠ¨è°ƒç”¨ä¹‹å‰è®¾ç½®çš„è½¬æ¢å‘é‡æ¨¡å‹æŠŠæ–‡æœ¬å—è½¬æ¢æˆå‘é‡
        leaf_nodes,
        storage_context=storage_context,
        show_progress=True,
    )

    print("\nğŸ‰ ================= Success ================= ğŸ‰")
    print(f"æ•°æ®å·²æˆåŠŸæ³¨å…¥ EduMatrixï¼")
    print(f"  - å‘é‡æ•°æ®åº“: Qdrant")
    print(f"  - é›†åˆåç§°: {COLLECTION_NAME}")
    print(f"  - åµŒå…¥æ¨¡å‹: BGE-M3")
    print("ä¸‹ä¸€æ­¥: ä½ å¯ä»¥å» Qdrant çš„ Dashboard (http://localhost:6333/dashboard) æŸ¥çœ‹æ•°æ®äº†ï¼")

if __name__ == "__main__":
    asyncio.run(main())