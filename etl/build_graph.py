import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from dotenv import load_dotenv
from pathlib import Path

from llama_index.llms.openai_like import OpenAILike
from llama_index.core import Settings, PropertyGraphIndex
from llama_index.readers.file import PyMuPDFReader
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore
from llama_index.core.indices.property_graph import SimpleLLMPathExtractor     # from llama_index.core.indices.property_graph import SchemaLLMPathExtractor åƒé—®ä¸Žopenaiæ ¼å¼ä¸åŒï¼Œä¸å…¼å®¹

load_dotenv()

PDF_PATH = Path(__file__).resolve().parents[1] / "data" / "æ·±åº¦å­¦ä¹ è¿›é˜¶_è‡ªç„¶è¯­è¨€å¤„ç†_æ–‹è—¤åº·æ¯….pdf"

NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "password123"
NEO4J_URI = "bolt://localhost:7687"

TEST_MODE = True

def main():
    print(f"ðŸš€ [Graph] å‡†å¤‡æž„å»ºçŸ¥è¯†å›¾è°±...")

    print(f"ðŸ¤– åˆå§‹åŒ– LLM: {os.getenv('DASHSCOPE_MODEL_NAME')}...")
    llm = OpenAILike(
        model=os.getenv("DASHSCOPE_MODEL_NAME") or "",
        api_base=os.getenv("DASHSCOPE_BASE_URL"),
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        is_chat_model=True, # å‘Šè¯‰ç³»ç»Ÿè¿™æ˜¯ä¸€ä¸ªå¯¹è¯æ¨¡åž‹
        context_window=32000, # æ¨¡åž‹ä¸€æ¬¡è¯»å–çš„å­—æ•°
    )
    Settings.llm = llm

    loader = PyMuPDFReader()
    documents = loader.load_data(file_path=PDF_PATH)
    
    """
    # âš ï¸ æµ‹è¯•æ¨¡å¼æˆªæ–­
    if TEST_MODE:
        print("âš¡ï¸ [æµ‹è¯•æ¨¡å¼] ä»…å¤„ç†å‰ 20 é¡µæ•°æ®...")
        documents = documents[30:45]
    """

    graph_store = Neo4jPropertyGraphStore(
        username=NEO4J_USER,
        password=NEO4J_PASSWORD,
        url=NEO4J_URI
    )

    print("ðŸ§  å¼€å§‹æå–çŸ¥è¯†å®žä½“ä¸Žå…³ç³» (Graph Extraction)...")
    print("â˜•ï¸ è¿™æ­¥æ¯”è¾ƒæ…¢ï¼ŒQwen æ­£åœ¨é˜…è¯»å¹¶æ•´ç†çŸ¥è¯†ç‚¹ï¼Œè¯·è€å¿ƒç­‰å¾…...")

    embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-m3",
        trust_remote_code=True,
        local_files_only=True,
    )

    kg_extractor = SimpleLLMPathExtractor(
        llm=llm,
        max_paths_per_chunk=15, # æ¯æ®µæ–‡æœ¬æœ€å¤šæå–15æ¡å…³ç³»ï¼Œé˜²æ­¢å¹»è§‰
        num_workers=4
    )

    index = PropertyGraphIndex.from_documents(  # æŠŠæ–‡æ¡£ï¼Œæå–å™¨ï¼Œå­˜å‚¨å™¨ä¸²è”èµ·æ¥ï¼Œæ‰§è¡Œæµæ°´çº¿å·¥ä½œ
        documents=documents,
        kg_extractors=[kg_extractor],
        embed_model=embed_model, # æ—¢å¯ä»¥åšå›¾æœç´¢ï¼Œä¹Ÿå¯ä»¥å¯¹å›¾ä¸Šçš„èŠ‚ç‚¹åšå‘é‡æœç´¢
        property_graph_store=graph_store,
        show_progress=True,
    )

    print("\nðŸŽ‰ ================= Success ================= ðŸŽ‰")
    print("çŸ¥è¯†å›¾è°±æž„å»ºå®Œæˆï¼")
    print(f"æ•°æ®å·²å­˜å…¥ Neo4jã€‚")
    print("ä¸‹ä¸€æ­¥: æ‰“å¼€æµè§ˆå™¨ http://localhost:7474 æŸ¥çœ‹ä½ çš„å›¾è°±ï¼")
    print("æŽ¨èæŸ¥è¯¢è¯­å¥: MATCH (n)-[r]->(m) RETURN n,r,m LIMIT 50")

if __name__ == "__main__":
    main()