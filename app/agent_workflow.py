from typing import Annotated, Dict, TypedDict, List, Any
from langgraph.graph import StateGraph, END
from llama_index.core.schema import NodeWithScore
from llama_index.core.llms import ChatMessage
from main import rag_engine

class AgentState(TypedDict):
    question: str # å½“å‰çš„é—®é¢˜ï¼ˆå¯èƒ½æ˜¯è¢«é‡å†™è¿‡çš„ç‰ˆæœ¬ï¼‰
    original_question: str # æœ€å¼€å§‹ç”¨æˆ·é—®çš„é—®é¢˜ï¼ˆæ²¡è¢«llmä¿®æ”¹è¿‡çš„ç‰ˆæœ¬ï¼‰ï¼›ç”¨äºæœ€ållmç”Ÿæˆå›ç­”
    chat_history: List[ChatMessage]
    retrieved_nodes: List[NodeWithScore]
    grade_status: str # "yes" or "no"
    retry_count: int
    final_response: Any

def create_graph_app(retriever, llm):
    """æ„å»ºå¹¶ç¼–è¯‘ LangGraph å·¥ä½œæµ"""
    # è¾…åŠ©å·¥å…·ï¼šæ„é€ è¯„åˆ†prompt
    def get_grader_prompt(question, context):
        return (
            f"ä½ æ˜¯ä¸€åè¯„åˆ†å‘˜ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æ£€ç´¢åˆ°çš„æ•™æç‰‡æ®µæ˜¯å¦ä¸ç”¨æˆ·çš„é—®é¢˜ç›¸å…³ã€‚\n"
            f"é—®é¢˜: {question}\n\n"
            f"æ•™æç‰‡æ®µ:\n{context}\n\n"
            f"å¦‚æœç‰‡æ®µåŒ…å«èƒ½å›ç­”é—®é¢˜çš„å…³é”®è¯æˆ–è¯­ä¹‰ï¼Œè¯·å›å¤ 'yes'ï¼Œå¦åˆ™å›å¤ 'no'ã€‚\n"
            f"åªå›å¤ 'yes' æˆ– 'no'ï¼Œä¸è¦åºŸè¯ã€‚"
        )
    
    async def retrieve_node(state: AgentState):
        print("ğŸ” [Node] Retrieving...")
        question = state["question"]
    
        nodes = await retriever.aretriever(question)

        print(f"   -> æ£€ç´¢åˆ° {len(nodes)} æ¡ç›¸å…³ç‰‡æ®µ")
        return {"retrieved_nodes": nodes}
    
    async def grade_node(state: AgentState):
        print("âš–ï¸ [Agent] æ­£åœ¨è¯„ä¼°èµ„æ–™è´¨é‡...")
        question = state["question"]
        nodes = state["retrieved_nodes"]

        # 1. å¦‚æœæ ¹æœ¬æ²¡æœåˆ°ï¼Œç›´æ¥åˆ¤æ­»åˆ‘
        if not nodes:
            return {"grade_status": "no"}
            
        # 2. æ„é€ ä¸Šä¸‹æ–‡ä¾› LLM åˆ¤æ–­
        # å–å‰ 3 ä¸ªç‰‡æ®µçš„å†…å®¹æ‹¼æ¥ï¼Œé¿å… token çˆ†ç‚¸
        context_preview = "\n".join([n.get_content()[:200] for n in nodes[:3]])

        prompt = get_grader_prompt(question, context_preview)

        # 3. è°ƒç”¨ LLM è¿›è¡ŒäºŒåˆ†ç±»
        # è¿™é‡Œç”¨ complete è€Œä¸æ˜¯ streamï¼Œå› ä¸ºæˆ‘ä»¬è¦æ‹¿ç»“æœåšåˆ¤æ–­
        response = await llm.acomplete(prompt)
        score = response.text.strip().lower()

        if "yes" in score:
            status = "yes"
        else:
            status = "no"
        
        print(f"   -> è¯„åˆ†ç»“æœ: {status}")
        return {"grade_status": status}
    
    async def rewrite_node(state: AgentState):
        print("ğŸ”„ [Agent] èµ„æ–™ä¸å…¨ï¼Œæ­£åœ¨é‡å†™æŸ¥è¯¢è¯...")
        question = state["question"]

        prompt = (
            f"ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š'{question}'ã€‚\n"
            f"ç›®å‰çš„æ£€ç´¢ç»“æœä¸ä½³ã€‚è¯·æ ¹æ®è¯­ä¹‰æŠŠè¿™ä¸ªé—®é¢˜é‡å†™å¾—æ›´ç²¾å‡†ï¼Œæˆ–è€…æ˜¯æå–æ ¸å¿ƒå…³é”®è¯ã€‚\n"
            f"åªè¾“å‡ºé‡å†™åçš„é—®é¢˜ï¼Œä¸è¦è§£é‡Šã€‚"
        )

        response = await llm.acomplete(prompt)
        new_question = response.text.strip()

        print(f"   -> æ–°é—®é¢˜: {new_question}")
        
        # æ›´æ–°é—®é¢˜ï¼Œå¹¶å¢åŠ è®¡æ•°å™¨
        return {
            "question": new_question, 
            "retry_count": state.get("retry_count", 0) + 1
        }
    
    async def generate_node(state: AgentState):
        print("âœï¸ [Agent] æ­£åœ¨ç»„ç»‡è¯­è¨€ç”Ÿæˆå›ç­” (Async)...")
        final_question = state["original_question"]
        nodes = state["retrieved_nodes"]
        history = state.get("chat_history", [])

        # 1. æ‹¼å‡‘ä¸Šä¸‹æ–‡
        context_str = "\n\n".join([f"---ç‰‡æ®µ---\n{n.get_content()}" for n in nodes])
        
        # 2. æ„é€  Prompt
        system_msg = ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¡ç®—æœºè¯¾ç¨‹åŠ©æ•™ã€‚è¯·æ ¹æ®æä¾›çš„æ•™æç‰‡æ®µå›ç­”é—®é¢˜ã€‚å¦‚æœç‰‡æ®µä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·è¯šå®å‘ŠçŸ¥ã€‚")
        user_msg = ChatMessage(role="user", content=f"å‚è€ƒèµ„æ–™ï¼š\n{context_str}\n\nç”¨æˆ·é—®é¢˜ï¼š{final_question}")
        
        messages = [system_msg] + history + [user_msg]

        response_stream = await llm.astream_chat(messages)

        return {"final_response": response_stream}
    
    workflow = StateGraph(AgentState)

    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("grade", grade_node)
    workflow.add_node("rewrite", rewrite_node)
    workflow.add_node("generate", generate_node)

    workflow.set_entry_point("retrieve")

    workflow.add_edge("retrieve", "grade")
    workflow.add_edge("rewrite", "retrieve")

    # --- å…³é”®é€»è¾‘ï¼šæ¡ä»¶è¾¹ ---
    def decide_next_step(state):
        status = state["grade_status"]
        retries = state.get("retry_count", 0)

        if status == "yes":
            return "generate" # èµ„æ–™å¤Ÿäº†ï¼Œå»ç”Ÿæˆ
        else:
            if retries < 1: # ğŸš¨ æœ€å¤šé‡è¯• 1 æ¬¡ï¼Œé˜²æ­¢æ­»å¾ªç¯
                return "rewrite"
            else:
                # è¯•è¿‡äº†è¿˜æ˜¯ä¸è¡Œï¼Œå¼ºè¡Œç”Ÿæˆï¼ˆæˆ–è€…è¿™å°±è¯¥å» Tavily äº†ï¼‰
                print("ğŸ›‘ [Agent] é‡è¯•æ¬¡æ•°è€—å°½ï¼Œå¼ºè¡Œç”Ÿæˆ...")
                return "generate"

    workflow.add_conditional_edges(
        "grade",
        decide_next_step,
        {
            "generate": "generate",
            "rewrite": "rewrite"
        }
    )

    workflow.add_edge("generate", END)

    app = workflow.compile()
    return app