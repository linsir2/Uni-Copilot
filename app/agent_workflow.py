import os
import httpx
import asyncio
from uuid import uuid4
from typing import List, Any, Dict, Optional
from llama_index.core.workflow import (
    Event, StartEvent, StopEvent, Workflow, step, Context
)
from llama_index.core.schema import NodeWithScore, TextNode
from llama_index.core.llms import ChatMessage

# ================= é…ç½®å¼€å…³ =================
ENABLE_WEB_SEARCH = os.getenv("ENABLE_WEB_SEARCH", "true").lower() == "true"
MAX_RETRIES = 1

# ================= å®šä¹‰äº‹ä»¶ (è¯­ä¹‰æ‹†åˆ†) =================
class GradeEvent(Event):
    """æ£€ç´¢å®Œæˆï¼Œç­‰å¾…è¯„åˆ†"""
    nodes: List[NodeWithScore]
    query: str

class RetryRequestEvent(Event):
    """è¯„åˆ†ä¸é€šè¿‡ï¼Œè¯·æ±‚é‡è¯•ï¼ˆä¸­é—´æ€ï¼‰"""
    original_query: str
    feedback: str

class RewriteEvent(Event):
    """é‡å†™å®Œæˆï¼Œæºå¸¦æ–° Queryï¼ˆç”¨äºè§¦å‘æ£€ç´¢ï¼‰"""
    original_query: str  # è¿™é‡Œçš„ semantic æ˜¯ "new query used for retrieval"
    feedback: str

class WebSearchEvent(Event):
    """æœ¬åœ°é‡è¯•è€—å°½ï¼Œè½¬ç½‘ç»œ"""
    query: str

class GenerateEvent(Event):
    """è¯„åˆ†é€šè¿‡ï¼Œå‡†å¤‡ç”Ÿæˆ"""
    nodes: List[NodeWithScore]
    source: str

# ================= å·¥ä½œæµå®šä¹‰ =================
class EduMatrixWorkflow(Workflow):
    def __init__(self, retriever, llm, timeout: int = 60, verbose: bool = True):
        super().__init__(timeout=timeout, verbose=verbose)
        self.retriever = retriever
        self.llm = llm
        
        # [å¹¶å‘å®‰å…¨] HTTP Client æ‡’åŠ è½½
        self._http_client: Optional[httpx.AsyncClient] = None
        self._client_lock = asyncio.Lock()

    async def _get_client(self) -> httpx.AsyncClient:
        if self._http_client is not None and not self._http_client.is_closed:
            return self._http_client 
        async with self._client_lock:
            if self._http_client is None or self._http_client.is_closed:
                self._http_client = httpx.AsyncClient(timeout=10.0)
            return self._http_client

    async def aclose(self):
        if self._http_client is not None and not self._http_client.is_closed:
            await self._http_client.aclose()
            self._http_client = None

    async def _tavily_search(self, query: str) -> List[NodeWithScore]:
        if not ENABLE_WEB_SEARCH: return []
        api_key = os.getenv("TAVILY_API_KEY")
        if not api_key: return []
        
        try:
            client = await self._get_client()
            resp = await client.post(
                url="https://api.tavily.com/search",
                json={
                    "api_key": api_key, "query": query,
                    "search_depth": "basic", "include_answer": True, "max_results": 3
                }
            )
            resp.raise_for_status()
            data = resp.json()

            nodes = []
            if data.get("answer"):
                nodes.append(NodeWithScore(
                    node=TextNode(text=f"ã€ç½‘ç»œæ‘˜è¦ã€‘: {data['answer']}", metadata={"file_name": "Web", "source": "web"}),
                    score=0.9 # ç»™é«˜åˆ†ï¼Œä¼˜å…ˆä½¿ç”¨
                ))
            for res in data.get("results", []):
                nodes.append(NodeWithScore(
                    node=TextNode(text=f"{res['content']}\n(Source: {res['url']})", metadata={"file_name": "Web", "source": "web"}),
                    score=0.8
                ))
            return nodes
        except Exception as e:
            print(f"âŒ Web Search Error: {e}")
            return []

    # --- Step 1: æ£€ç´¢ (ç›‘å¬ Start æˆ– Rewrite å®Œæˆäº‹ä»¶) ---
    @step
    async def retrieve(self, ctx: Context, ev: StartEvent | RewriteEvent) -> GradeEvent:
        trace_id = await ctx.get("trace_id", default=uuid4().hex[:8])
        
        if isinstance(ev, StartEvent):
            question = ev.get("question")
            await ctx.set("trace_id", trace_id) # type: ignore
            await ctx.set("original_question", question) # type: ignore
            await ctx.set("chat_history", ev.get("chat_history", [])) # type: ignore
            await ctx.set("retry_count", 0) # type: ignore
            search_query = question
            print(f"[{trace_id}] ğŸš€ Start: {search_query}")
        else:
            # è¿™é‡Œçš„ ev æ˜¯ RewriteEventï¼Œæºå¸¦çš„æ˜¯å·²ç»æ”¹å†™å¥½çš„æ–° query
            search_query = ev.original_query
            print(f"[{trace_id}] ğŸ”„ Rewritten Retrieval: {search_query}")

        nodes = await self.retriever.aretrieve(search_query)
        # [ä¼˜åŒ–] é™åˆ¶ä¸Šä¸‹æ–‡æ•°é‡ï¼Œé˜²æ­¢ Token çˆ†ç‚¸
        return GradeEvent(nodes=nodes[:10], query=search_query)

    # --- Step 2: è¯„åˆ† ---
    @step
    async def grade(self, ctx: Context, ev: GradeEvent) -> GenerateEvent | RetryRequestEvent | WebSearchEvent:
        trace_id = await ctx.get("trace_id")
        nodes = ev.nodes
        if not nodes:
            return await self._handle_retry(ctx, ev.query, "No content")

        preview = "\n".join([n.node.get_content()[:200] for n in nodes[:5]])
        # [ä¼˜åŒ–] Prompt çº¦æŸï¼Œåªè¾“å‡º yes/no
        prompt = (
            f"é—®é¢˜: {ev.query}\nç‰‡æ®µ: {preview}\n"
            f"åˆ¤æ–­ç‰‡æ®µæ˜¯å¦åŒ…å«å›ç­”é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ã€‚\n"
            f"è§„åˆ™ï¼š\n1. åŒ…å«å®šä¹‰ã€æ•°æ®æˆ–è§£é‡Š -> yes\n2. ä»…æåŠå…³é”®è¯ä½†æ— å†…å®¹ -> no\n"
            f"è¯·ä»…å›ç­” 'yes' æˆ– 'no' (ä¸è¦å¸¦æ ‡ç‚¹)ã€‚"
        )
        res = await self.llm.acomplete(prompt)
        
        score_raw = res.text.strip().lower()
        # [ä¼˜åŒ–] æ›´ç¨³çš„åˆ¤æ–­
        is_relevant = score_raw == "yes" or score_raw.startswith("yes")
        
        if is_relevant:
            print(f"[{trace_id}] âœ… Grade Pass")
            return GenerateEvent(nodes=nodes, source="local")
        
        print(f"[{trace_id}] âŒ Grade Fail: {score_raw}")
        return await self._handle_retry(ctx, ev.query, "Irrelevant content")

    async def _handle_retry(self, ctx: Context, query: str, reason: str):
        retry_count = await ctx.get("retry_count")
        if retry_count < MAX_RETRIES:
            await ctx.set("retry_count", retry_count + 1) # type: ignore
            # [å…³é”®ä¿®å¤] å‘å‡º RetryRequestEventï¼Œè€Œä¸æ˜¯ç›´æ¥å‘ RewriteEventï¼Œé¿å…æ­»å¾ªç¯
            return RetryRequestEvent(original_query=query, feedback=reason)
        return WebSearchEvent(query=await ctx.get("original_question"))

    # --- Step 3: é‡å†™ (ç›‘å¬ RetryRequestEvent) ---
    @step
    async def rewrite(self, ctx: Context, ev: RetryRequestEvent) -> RewriteEvent:
        trace_id = await ctx.get("trace_id")
        print(f"[{trace_id}] ğŸ§  Rewriting query...")
        
        prompt = (
            f"åŸé—®é¢˜ '{ev.original_query}' æ£€ç´¢å¤±è´¥ã€‚\n"
            f"è¯·æå–æ ¸å¿ƒå®ä½“ï¼Œå»é™¤ä¿®é¥°è¯ï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„æœç´¢å…³é”®è¯ã€‚\n"
            f"ä»…è¾“å‡ºå…³é”®è¯ï¼Œä¸è¶…è¿‡15å­—ã€‚"
        )
        res = await self.llm.acomplete(prompt)
        new_q = res.text.strip()
        
        # [å…³é”®] è¿”å› RewriteEventï¼Œè¿™ä¸ªäº‹ä»¶åªè¢« Retrieve ç›‘å¬
        return RewriteEvent(original_query=new_q, feedback="refined")

    # --- Step 4: è”ç½‘ ---
    @step
    async def web_search(self, ctx: Context, ev: WebSearchEvent) -> GenerateEvent:
        trace_id = await ctx.get("trace_id")
        print(f"[{trace_id}] ğŸŒ Web Fallback: {ev.query}")
        nodes = await self._tavily_search(ev.query)
        return GenerateEvent(nodes=nodes, source="web")

    # --- Step 5: ç”Ÿæˆ ---
    @step
    async def generate(self, ctx: Context, ev: GenerateEvent) -> StopEvent:
        nodes = ev.nodes
        original_q = await ctx.get("original_question")
        
        serialized_nodes = []
        context_lines = []
        
        # [ä¼˜åŒ–] å†æ¬¡é™åˆ¶è¿›å…¥ LLM çš„ç‰‡æ®µæ•°é‡ï¼Œç¡®ä¿ç²¾ç®€
        for n in nodes[:8]:
            meta = n.node.metadata or {}
            text = n.node.get_content()
            citation = "[Web]" if ev.source == "web" else f"[{meta.get('file_name','Doc')} P{meta.get('page','?')}]"
            context_lines.append(f"å¼•ç”¨ {citation}:\n{text}\n")
            
            serialized_nodes.append({
                "text": text,
                "metadata": meta,
                "score": n.score
            })

        if not serialized_nodes:
            return StopEvent(result={"final_response": "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚", "retrieved_nodes": []})

        sys_msg = ChatMessage(role="system", content="åŸºäºèµ„æ–™å›ç­”ã€‚å¿…é¡»æ ‡æ³¨å¼•ç”¨æ¥æºï¼Œå¦‚ [Doc P1]ã€‚")
        user_msg = ChatMessage(role="user", content=f"èµ„æ–™:\n{''.join(context_lines)}\n\né—®é¢˜: {original_q}")
        
        stream = await self.llm.astream_chat([sys_msg, user_msg])
        
        return StopEvent(result={
            "final_response": stream, 
            "retrieved_nodes": serialized_nodes
        })

def create_graph_app(retriever, llm):
    return EduMatrixWorkflow(retriever=retriever, llm=llm, timeout=120, verbose=True)