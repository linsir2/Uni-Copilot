import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.responses import StreamingResponse
from .agent_workflow import create_graph_app

# LlamaIndex æ ¸å¿ƒç»„ä»¶
from llama_index.core import Settings, VectorStoreIndex, PropertyGraphIndex
from llama_index.llms.dashscope import DashScope
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.llms import ChatMessage
from llama_index.core.retrievers import BaseRetriever

# æ•°æ®åº“ç»„ä»¶
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore
import qdrant_client

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®å‚æ•°
QDRANT_URL = "http://localhost:6333"
QDRANT_COLLECTION = "edu_matrix_v2"
NEO4J_URL = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD") or ""

# å…¨å±€å¼•æ“å®¹å™¨
rag_engine = {}

# ==========================================
# ğŸ”§ å·¥å…·ç±»å®šä¹‰
# ==========================================

class HybridRetriever(BaseRetriever):
    """
    æ··åˆæ£€ç´¢å™¨ï¼šåŒæ—¶ä» Vector (Qdrant) å’Œ Graph (Neo4j) æ£€ç´¢ï¼Œå¹¶åˆå¹¶ç»“æœã€‚
    """
    def __init__(self, vector_retriever, graph_retriever):
        self.vector_retriever = vector_retriever
        self.graph_retriever = graph_retriever
        super().__init__()
    
    def _retrieve(self, query_bundle):
        # 1. å¹¶è¡Œæ£€ç´¢
        nodes_vect = self.vector_retriever.retrieve(query_bundle)
        nodes_graph = self.graph_retriever.retrieve(query_bundle)
        
        # 2. åˆå¹¶å»é‡ (åŸºäº node_id)
        combined_dict = {n.node.node_id: n for n in (nodes_vect + nodes_graph)}
        return list(combined_dict.values())

# ==========================================
# ğŸš€ ç”Ÿå‘½å‘¨æœŸç®¡ç† (åˆå§‹åŒ–æ ¸å¿ƒ)
# ==========================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ [Startup] æ­£åœ¨åˆå§‹åŒ– EduMatrix å¼•æ“...")
    
    try:
        # 1. åˆå§‹åŒ–æ¨¡å‹ (Embedding + LLM)
        print("ğŸ§  åŠ è½½æ¨¡å‹ (Embedding: BGE-M3, LLM: Qwen)...")
        embed_model = HuggingFaceEmbedding(
            model_name="BAAI/bge-m3",
            trust_remote_code=True,
            local_files_only=True,
            device="cpu",
        )
        Settings.embed_model = embed_model

        llm = DashScope(
            model_name=os.getenv("DASHSCOPE_MODEL_NAME"),
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            temperature=0.1,
        )
        rag_engine["llm"] = llm

        # 2. è¿æ¥ Qdrant (è´Ÿè´£åŸæ–‡æ£€ç´¢)
        print("ğŸ”Œ è¿æ¥ Qdrant (Vector Store)...")
        qdrant_client_obj = qdrant_client.QdrantClient(url=QDRANT_URL)
        vector_store = QdrantVectorStore(
            collection_name=QDRANT_COLLECTION,
            client=qdrant_client_obj,
        )
        vector_index = VectorStoreIndex.from_vector_store(vector_store=vector_store)

        # 3. è¿æ¥ Neo4j (è´Ÿè´£å…³ç³»æ£€ç´¢)
        print("ğŸ”Œ è¿æ¥ Neo4j (Graph Store)...")
        graph_store = Neo4jPropertyGraphStore(
            username=NEO4J_USER,
            password=NEO4J_PASSWORD,
            url=NEO4J_URL,
        )
        graph_index = PropertyGraphIndex.from_existing(
            property_graph_store=graph_store,
            llm=llm
        )

        rag_engine["graph_store"] = graph_store

        # 4. æ„å»ºæ··åˆæ£€ç´¢ç­–ç•¥
        # A. å‘é‡æ£€ç´¢å·¥å…·
        vector_tool = vector_index.as_retriever(similarity_top_k=5)
        
        # B. å›¾è°±æ£€ç´¢å·¥å…· (ä½¿ç”¨ VectorContextRetriever è¿›è¡Œå®šä½ + æ‰©æ•£)
        from llama_index.core.retrievers import VectorContextRetriever
        sub_retriever = VectorContextRetriever(
            graph_store=graph_store,
            similarity_top_k=5,
            path_depth=3 # æŠ“å– 3 è·³é‚»å±…
        )
        graph_tool = graph_index.as_retriever(
            sub_retrievers=[sub_retriever]
        )

        # C. ç»„è£…æ··åˆæ£€ç´¢å™¨
        hybrid_retriever = HybridRetriever(vector_tool, graph_tool)

        # 5. ğŸ”¥ æ„å»º Agent (æ›¿æ¢åŸæ¥çš„ ChatEngine)
        print("ğŸ¤– æ„å»º LangGraph Agent...")
        # æŠŠ llm å’Œ retriever ä¼ è¿›å»
        graph_app = create_graph_app(hybrid_retriever, llm)

        rag_engine["graph_app"] = graph_app
        print("âœ… å¼•æ“åˆå§‹åŒ–å®Œæˆï¼ç­‰å¾…è¯·æ±‚...")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        raise e

    yield 
    print("ğŸ‘‹ [Shutdown] æœåŠ¡å™¨å·²å…³é—­")

# ==========================================
# ğŸ“¡ API æ¥å£å®šä¹‰
# ==========================================

app = FastAPI(title="EduMatrix API", lifespan=lifespan)

class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: list[Message]

@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest):
    if not rag_engine:
        raise HTTPException(status_code=500, detail="Engine not initialized")
    
    # 1. è§£æè¯·æ±‚
    last_message = request.messages[-1].content
    print(f"ğŸ“© æ”¶åˆ°é—®é¢˜: {last_message}")

    # 2. å‡†å¤‡å†å²è®°å½•
    chat_history = [
        ChatMessage(role=m.role, content=m.content)
        for m in request.messages[:-1]
    ]

    inputs = {
    "question": last_message,
    "original_question": last_message, # âœ… æ–°å¢è¿™ä¸ª
    "chat_history": chat_history,
    "retrieved_nodes": [],
    "grade_status": "",
    "retry_count": 0, # âœ… åˆå§‹åŒ–è®¡æ•°å™¨
    "final_response": ""
}

    # è¿è¡Œå›¾è°±ï¼Œç›´åˆ°ç»“æŸ
    # æ³¨æ„ï¼šæˆ‘ä»¬çš„ generate_node è¿”å›çš„æ˜¯ä¸€ä¸ª stream iterator å¯¹è±¡
    result = await rag_engine["graph_app"].ainvoke(inputs)

    streaming_response = result["final_response"]

    # 4. ç”Ÿæˆæµå¼å“åº”
    async def response_generator():
        # A. åå‡º AI å›ç­”
        # situation A: å¦‚æœæ˜¯æ™®é€šå­—ç¬¦ä¸² (æ¥è‡ª Apologize Node)
        if isinstance(streaming_response, str):
            yield streaming_response
            
        # situation B: å¦‚æœæ˜¯æµå¼å“åº”å¯¹è±¡ (æ¥è‡ª Generate Node)
        elif hasattr(streaming_response, "async_response_gen"):
            async for token in streaming_response.async_response_gen():
                yield token.delta
        
        # situation C: å…œåº• (æœ‰äº›ç‰ˆæœ¬çš„ LlamaIndex è¿”å›çš„æ˜¯ç›´æ¥çš„ AsyncGenerator)
        else:
            try:
                async for token in streaming_response:
                    yield token.delta
            except Exception as e:
                yield f"âŒ å“åº”è§£æé”™è¯¯: {str(e)}"

        
        # B. åå‡ºå‚è€ƒæ¥æº (å¦‚æœæœ‰)
        nodes = result.get("retrieved_nodes", [])
        if nodes:
            yield "\n\n---\n**ğŸ§  æ€è€ƒè·¯å¾„ï¼š**\n"
            yield f"- æ£€ç´¢åˆ° {len(nodes)} ä¸ªçŸ¥è¯†ç‰‡æ®µ\n"
            yield "- æ­£åœ¨åŸºäº Graph + Vector è¿›è¡Œæ¨ç†...\n"
                
            yield "\n**ğŸ“š å‚è€ƒæ¥æºï¼š**\n"
            seen = set()
            for n in nodes:
                txt = n.get_content()[:50].replace('\n', ' ')
                if txt not in seen:
                    yield f"> {txt}...\n"
                    seen.add(txt)
            
    return StreamingResponse(response_generator(), media_type="text/plain")

@app.get("/")
def read_root():
    return {"message": "EduMatrix API is running! Go to /docs for Swagger UI."}
# ç¡®ä¿åœ¨æ–‡ä»¶é¡¶éƒ¨æœ‰è¿™ä¸ªå¯¼å…¥
from neo4j import GraphDatabase

@app.post("/api/graph")
async def get_graph(request: ChatRequest):
    # é»˜è®¤è¿”å›å€¼
    result_data = {"links": []}
    
    try:
        # 1. å®‰å…¨è·å–å…³é”®è¯
        if not request.messages or not request.messages[-1].content:
            print("âš ï¸ [Graph API] æ”¶åˆ°ç©ºæ¶ˆæ¯")
            return result_data
            
        user_query = request.messages[-1].content
        print(f"ğŸ“© [Graph API] ç”¨æˆ·åŸå§‹æé—®: {user_query}")

        # å®šä¹‰æå– Promptï¼Œå¼ºåˆ¶è¦æ±‚æ ¼å¼ç®€æ´
        extract_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸ä»…æ‡‚ä¸­æ–‡ï¼Œè¿˜æ‡‚è®¡ç®—æœºç§‘å­¦çš„å®ä½“æå–åŠ©æ‰‹ã€‚\n"
            "è¯·ä»ç”¨æˆ·çš„æé—®ä¸­æå–å‡º 1 åˆ° 3 ä¸ªæœ€æ ¸å¿ƒçš„ã€å®ä½“å…³é”®è¯ã€‘ï¼Œç”¨äºåœ¨çŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ã€‚\n"
            "è¦æ±‚ï¼š\n"
            "1. åªè¿”å›å…³é”®è¯ï¼Œç”¨é€—å· ',' åˆ†éš”ã€‚\n"
            "2. å»æ‰æ‰€æœ‰ä¿®é¥°è¯ï¼ˆå¦‚'è¯·é—®'ã€'æ˜¯ä»€ä¹ˆ'ã€'ä»‹ç»ä¸€ä¸‹'ï¼‰ã€‚\n"
            "3. å¦‚æœæ²¡æœ‰æ˜æ˜¾å®ä½“ï¼Œæå–æœ€å…³é”®çš„åè¯ã€‚\n"
            "4. ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–åºŸè¯ã€‚\n"
            "\n"
            f"ç”¨æˆ·æé—®ï¼š{user_query}\n"
            "å…³é”®è¯ï¼š"
        )

        response = await rag_engine["llm"].acomplete(extract_prompt)
        llm_output = response.text.strip()

        # æ¸…æ´— LLM è¾“å‡ºï¼šæŒ‰é€—å·åˆ†å‰² -> å»ç©º -> å»é‡
        keywords = [k.strip() for k in llm_output.split(',') if k.strip()]
        
        # å†æ¬¡å…œåº•ï¼šå¦‚æœ LLM å•¥éƒ½æ²¡åå‡ºæ¥
        if not keywords:
            keywords = [user_query]
        
        print(f"ğŸ” [Graph API] LLM æå–çš„å…³é”®è¯: {keywords}")

        # Cypher è§£é‡Šï¼š
        # ANY(k IN $keywords WHERE ...) : åªè¦èŠ‚ç‚¹åå­—åŒ…å«åˆ—è¡¨é‡Œçš„ä»»æ„ä¸€ä¸ªè¯ï¼Œå°±åŒ¹é…
        # toLower(...) : å¿½ç•¥å¤§å°å†™
        # type(r) <> 'MENTIONS' : è¿‡æ»¤æ‰é‚£äº›æ²¡æœ‰è¯­ä¹‰çš„å¼•ç”¨è¿çº¿
        cypher_sql = """
        MATCH (n)-[r]->(m)
        WHERE (
            ANY(k IN $keywords WHERE toLower(n.id) CONTAINS toLower(k)) 
            OR 
            ANY(k IN $keywords WHERE toLower(m.id) CONTAINS toLower(k))
        )
        AND type(r) <> 'MENTIONS'
        RETURN n.id AS source, type(r) AS label, m.id AS target
        LIMIT 30
        """
        
        # 3. è¿æ¥æ•°æ®åº“
        # è¯·ç¡®ä¿ NEO4J_URL, NEO4J_USER, NEO4J_PASSWORD å˜é‡å·²å®šä¹‰
        driver = GraphDatabase.driver(NEO4J_URL, auth=(NEO4J_USER, NEO4J_PASSWORD))
        
        with driver.session() as session:
            result = session.run(cypher_sql, keywords=keywords)
            records = [record.data() for record in result]
            print(f"âœ… Neo4j æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ° {len(records)} æ¡å…³ç³»")
            result_data["links"] = records
            
        driver.close()

    except Exception as e:
        # ğŸ”¥ å…³é”®ï¼šæ‰“å°è¯¦ç»†é”™è¯¯ï¼Œæ–¹ä¾¿ä½ åœ¨ç»ˆç«¯çœ‹åˆ°
        import traceback
        traceback.print_exc() 
        print(f"âŒ Neo4j æŸ¥è¯¢å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        # å³ä½¿å‡ºé”™ï¼Œresult_data ä¹Ÿæ˜¯ {"links": []}ï¼Œä¸ä¼šæ˜¯ None

    # ğŸ”¥ å…³é”®ï¼šæ— è®º try é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Œè¿™é‡Œä¸€å®šä¼šè¿”å›ä¸€ä¸ªå­—å…¸
    return result_data