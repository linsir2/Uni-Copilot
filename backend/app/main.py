import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import time
import traceback
import shutil
import hashlib
import json
import gzip
import dashscope
from qdrant_client import QdrantClient
from qdrant_client.http import models as rest
from contextlib import asynccontextmanager
from pathlib import Path
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from neo4j import GraphDatabase
from redis import asyncio as aioredis
from redis.asyncio import Redis

from core.edu_parser.base import MultimodalAgenticRAGPack
from worker import parse_pdf

load_dotenv()

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
if not DATA_DIR.exists(): 
    os.makedirs(DATA_DIR, exist_ok=True)

print(f"ðŸ“‚ [Config] DATA_DIR set to: {DATA_DIR}")

# Configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://127.0.0.1:8000")
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
NEO4J_URL = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")

rag_pack: MultimodalAgenticRAGPack
redis_client: Redis | None = None
neo4j_driver = None  # Kept separate for the raw graph visualization endpoint
qdrant_client = None

SEMANTIC_COLLECTION = "graph_query_cache"

async def get_query_embedding(text: str):
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        return None
    
    try:
        resp = dashscope.TextEmbedding.call(
            model=dashscope.TextEmbedding.Models.text_embedding_v2,
            input=text,
            api_key=api_key,
        )
        if resp.status_code == 200:
            return resp.output["embeddings"][0]["embedding"]
    except Exception as e:
        print(f"âš ï¸ Embedding Error: {e}")
    return []

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ðŸš€ [Startup] Initializing Retrieval RAG Pack...")
    global redis_client, neo4j_driver, rag_pack, qdrant_client

    try:
        rag_pack = MultimodalAgenticRAGPack(
            qdrant_url=os.getenv("QDRANT_URL", "http://localhost:6333"),
            qdrant_api_key=os.getenv("QDRANT_API_KEY"),
            neo4j_url=NEO4J_URL,
            neo4j_username=NEO4J_USER,
            neo4j_password=NEO4J_PASSWORD,
            dashscope_api_key=os.getenv("DASHSCOPE_API_KEY"),
            tavily_api_key=os.getenv("TAVILY_API_KEY"),
            data_dir=str(DATA_DIR),
        )

        redis_client = await aioredis.from_url(REDIS_URL, encoding="utf-8", decode_responses=True)

        neo4j_driver = GraphDatabase.driver(
            NEO4J_URL, auth=(NEO4J_USER, NEO4J_PASSWORD)
        )

        qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
        qdrant_client = QdrantClient(url=qdrant_url, api_key=os.getenv("QDRANT_API_KEY"), prefer_grpc=False)

        if not qdrant_client.collection_exists(SEMANTIC_COLLECTION):
            print(f"ðŸ“¦ Creating Semantic Cache Collection: {SEMANTIC_COLLECTION}")
            qdrant_client.create_collection(
                collection_name=SEMANTIC_COLLECTION,
                vectors_config=rest.VectorParams(
                    size=1536, # ðŸ”¥ æ³¨æ„ï¼šDashScope text-embedding-v2 æ˜¯ 1536 ç»´
                    distance=rest.Distance.COSINE
                )
            )

        print("âœ… Retrieval Engine Ready!")

    except Exception as e:
        print(f"âŒ Startup Error: {e}")
        traceback.print_exc()

    yield

    if neo4j_driver:
        neo4j_driver.close()
    if redis_client:
        await redis_client.aclose()
    if qdrant_client:
        qdrant_client.close()

app = FastAPI(title="EduMatrix API", lifespan=lifespan)

# Static Files Setup
app.mount("/static", StaticFiles(directory=DATA_DIR), name="static")

class ChatRequest(BaseModel):
    messages: list[dict]

@app.post("/api/upload")
async def upload_pdf(file: UploadFile = File(...)):
    """
    ä¸Šä¼  PDF -> Celery Ingestion
    """
    # 1. ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    upload_dir = DATA_DIR / "uploads"
    if not upload_dir.exists():
        upload_dir.mkdir(parents=True, exist_ok=True)

    file_content = await file.read()
    file_hash = hashlib.md5(file_content).hexdigest()
    await file.seek(0)

    cache_key = f"pdf:task:{file_hash}"
    if redis_client:
        existing_task_id = await redis_client.get(cache_key)
        if existing_task_id:
            return {
                "status": "cached",
                "task_id": existing_task_id,
                "message": f"âš¡ ç§’ä¼ æˆåŠŸï¼{file.filename} ä¹‹å‰å·²ä¸Šä¼ è¿‡ã€‚",
            }
        
    # 2. ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°
    file_path = upload_dir / (file.filename or "")
    try:
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"File save failed: {e}")

    # 3. å‘é€ç»™Celery
    task = parse_pdf.delay(str(file_path))

    if redis_client:
        await redis_client.set(
            cache_key,
            task.id,
            ex=24 * 3600,
        )
    return {
        "status": "queued",
        "task_id": task.id,
        "message": f"{file.filename} å·²åŠ å…¥è§£æžé˜Ÿåˆ—"
    }

@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest):
    last_msg = request.messages[-1]["content"]
    
    # Run the Pack (it handles retrieval -> grading -> generation internally)
    try:
        result = await rag_pack.run(query=last_msg)
        streaming_response = result["final_response"]
        retrieved_nodes = result["retrieved_nodes"]
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

    async def response_generator():
        try:
            # 1. Stream the LLM response
            iterator = streaming_response
            if hasattr(streaming_response, "async_response_gen"):
                iterator = streaming_response.async_response_gen()

            async for token in iterator:
                text = getattr(token, "delta", None) or getattr(token, "text", None)
                if text:
                    yield text

            # 2. Append Citations & Images (Frontend logic)
            if retrieved_nodes:
                yield "\n\n---\n**ðŸ§  Thinking Process:**\n"
                seen_texts = set()
                seen_images = set()
            
                for n in retrieved_nodes:
                    meta = n.get("metadata", {})
                    content = n.get("text", "")
                    
                    # Text Citation
                    preview = content[:50].replace('\n', ' ')
                    if preview not in seen_texts:
                        yield f"> **[{meta.get('file_name','Doc')} P{meta.get('page_label', meta.get('page','?'))}]**: {preview}...\n"
                        seen_texts.add(preview)

                    # Image Citation
                    fname = meta.get("file_name", "")
                    if fname not in ["Web", "Textbook"]:
                        try:
                            safe_name = Path(fname).stem.replace(" ", "_")
                            page_idx = meta.get("page_label", meta.get("page", "?"))
                        
                            # Check local storage for images associated with this page
                            img_dir = DATA_DIR / "parser_cache" / safe_name / "images"
                            prefix = f"p{page_idx}_"

                            print(f"ðŸ” [ImgDebug] å¯»æ‰¾å›¾ç‰‡: {prefix} in {img_dir}")
                            if img_dir.exists():
                                for f in os.listdir(img_dir):
                                    if f.startswith(prefix) and f.lower().endswith(('.jpg', '.png', '.jpeg')):
                                        img_url = f"{API_BASE_URL}/static/parser_cache/{safe_name}/images/{f}"
                                        if img_url not in seen_images:
                                            print(f"âœ… [ImgDebug] æ‰¾åˆ°å›¾ç‰‡: {img_url}")
                                            yield f"\n![Page {page_idx}]({img_url})\n"
                                            seen_images.add(img_url)
                            else:
                                 print(f"âŒ [ImgDebug] ç›®å½•ä¸å­˜åœ¨: {img_dir}")

                        except Exception as e:
                            print(f"âš ï¸ Image Error: {e}")
                            traceback.print_exc()
        except Exception as e:
            yield "\n\nâš ï¸ å‡ºçŽ°é”™è¯¯ï¼Œè¯·ç¨åŽå†è¯•"
            traceback.print_exc()

    return StreamingResponse(response_generator(), media_type="text/plain")

@app.post("/api/graph")
async def get_graph(request: ChatRequest):
    """
    Extracts keywords using the Pack's LLM and queries Neo4j for visualization.
    """
    result_data = {"links": []}
    if not request.messages: return result_data
    
    query = request.messages[-1]["content"]

    query_hash = hashlib.md5(query.strip().lower().encode("utf-8")).hexdigest()
    CACHE_VERSION = "v1"
    cache_key = f"graph:{CACHE_VERSION}:{query_hash}"

    try:
        query_vec = await get_query_embedding(query)

        if query_vec and len(query_vec) == 1536 and qdrant_client:
            version_filter = rest.Filter(
                must=[
                    rest.FieldCondition(
                        key="cache_version",
                        match=rest.MatchValue(value=CACHE_VERSION)
                    ),
                    rest.FieldCondition(
                        key="model",
                        match=rest.MatchValue(value="dashscope-v2")
                    )
                ]
            )

            search_res = qdrant_client.query_points(
                collection_name=SEMANTIC_COLLECTION,
                query=query_vec,
                limit=1,
                score_threshold=0.86,
                query_filter=version_filter,
            )

            if search_res and hasattr(search_res, "points") and len(search_res.points) > 0:
                hit = search_res.points[0]
                payload_data = hit.payload or {}
                cached_graph = payload_data.get("graph_data")
                original_q = payload_data.get("query")
                
                if cached_graph:
                    print(f"âš¡ [Semantic Hit] '{query}' â‰ˆ '{original_q}' (sim: {hit.score:.4f})")
                    if redis_client:
                        query_hash = hashlib.md5(query.strip().lower().encode("utf-8")).hexdigest()
                        cache_key = f"graph:v1:{query_hash}"
                        # åŽ‹ç¼©å¹¶å†™å›ž Redis
                        compressed = gzip.compress(json.dumps(cached_graph).encode("utf-8"))
                        await redis_client.set(cache_key, compressed, ex=3600)
                    return cached_graph
            else:
                print(f"â„¹ï¸ [Semantic Cache] No similar query found above 0.86 threshold.")
    except Exception as e:
        print(f"âš ï¸ Semantic Cache Check Failed: {e}")
  
    if redis_client:
        cached_data = await redis_client.get(cache_key)
        if cached_data:
            try:
                decompressed = gzip.decompress(cached_data).decode("utf-8")
                print(f"âš¡ [Cache Hit] Graph served from Redis for: {query}")
                return json.loads(decompressed)
            except Exception:
                pass
        
    print(f"ðŸ¢ [Cache Miss] Generating Graph for: {query}")

    try:
        # Use the LLM instance directly from the Pack
        prompt = f"Extract 1-3 technical entities from '{query}', comma separated. No intro/outro."
        res = await rag_pack.llm.acomplete(prompt)
        keywords = [k.strip() for k in res.text.split(',') if k.strip()] or [query]

        cypher = """
        MATCH (n)-[r]->(m)
        WHERE ANY(k IN $kw WHERE toLower(COALESCE(n.name, n.text, '')) CONTAINS toLower(k))
           OR ANY(k IN $kw WHERE toLower(COALESCE(m.name, m.text, '')) CONTAINS toLower(k))

        RETURN 
            COALESCE(
                n.name, 
                CASE WHEN n.file_name IS NOT NULL THEN n.file_name + ' (P' + toString(n.page_label) + ')' END, 
                'Unknown Node'
            ) AS source,
    
            type(r) AS label,
    
            COALESCE(
                m.name, 
                CASE WHEN m.file_name IS NOT NULL THEN m.file_name + ' (P' + toString(m.page_label) + ')' END, 
                'Unknown Node'
            ) AS target
        LIMIT 30
        """
        
        if neo4j_driver:
            with neo4j_driver.session() as session:
                result_data["links"] = session.execute_read(
                    lambda tx: [r.data() for r in tx.run(cypher, kw=keywords)]
                )
        
        if result_data["links"]:
            # 1. å­˜å…¥ Redis (çŸ­æœŸç²¾ç¡®ç¼“å­˜)
            if redis_client:
                compressed = gzip.compress(json.dumps(result_data).encode("utf-8"))
                await redis_client.set(cache_key, compressed, ex=3600)
            
            semantic_id = hashlib.md5(
                (query.strip().lower() + "|dashscope-v2" + CACHE_VERSION).encode("utf-8")
            ).hexdigest()

            # 2. å­˜å…¥ Qdrant (é•¿æœŸè¯­ä¹‰ç¼“å­˜)
            if query_vec and qdrant_client:
                qdrant_client.upsert(
                    collection_name=SEMANTIC_COLLECTION,
                    points=[
                        rest.PointStruct(
                            id=semantic_id,
                            vector=query_vec,
                            payload={
                                "query": query,
                                "graph_data": result_data,
                                "created_at": time.time(),
                                "model": "dashscope-v2",
                                "cache_version": CACHE_VERSION,
                            }
                        )
                    ]
                )
                
    except Exception as e:
        print(f"Graph Error: {e}")
        
    return result_data